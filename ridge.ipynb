{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:51.699382Z",
     "iopub.status.busy": "2025-07-24T13:51:51.698787Z",
     "iopub.status.idle": "2025-07-24T13:51:51.707666Z",
     "shell.execute_reply": "2025-07-24T13:51:51.706878Z",
     "shell.execute_reply.started": "2025-07-24T13:51:51.699360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\n",
      "/kaggle/input/drw-crypto-market-prediction/train.parquet\n",
      "/kaggle/input/drw-crypto-market-prediction/test.parquet\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results__.html\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__notebook__.ipynb\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__output__.json\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/custom.css\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___14_1.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___14_0.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___22_0.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___29_1.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___25_1.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___29_0.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___34_0.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___25_2.png\n",
      "/kaggle/input/drw-crypto-market-prediction-comprehensive-eda/__results___files/__results___22_1.png\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:51.880978Z",
     "iopub.status.busy": "2025-07-24T13:51:51.880740Z",
     "iopub.status.idle": "2025-07-24T13:51:51.885789Z",
     "shell.execute_reply": "2025-07-24T13:51:51.885017Z",
     "shell.execute_reply.started": "2025-07-24T13:51:51.880960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:52.196789Z",
     "iopub.status.busy": "2025-07-24T13:51:52.196058Z",
     "iopub.status.idle": "2025-07-24T13:51:52.200093Z",
     "shell.execute_reply": "2025-07-24T13:51:52.199560Z",
     "shell.execute_reply.started": "2025-07-24T13:51:52.196754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    \"buy_qty\", \"sell_qty\", \"volume\", \"bid_qty\", \"ask_qty\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:52.310942Z",
     "iopub.status.busy": "2025-07-24T13:51:52.310759Z",
     "iopub.status.idle": "2025-07-24T13:51:52.316242Z",
     "shell.execute_reply": "2025-07-24T13:51:52.315522Z",
     "shell.execute_reply.started": "2025-07-24T13:51:52.310928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# XGB feature importance\n",
    "\n",
    "def get_xgb_top_features(train_df, label_column, top_k=50):\n",
    "    X = train_df.drop(columns=[label_column]).values\n",
    "    y = train_df[label_column].values\n",
    "    model = XGBRegressor(n_estimators=100, random_state=42, tree_method=\"hist\")\n",
    "    model.fit(X, y)\n",
    "    imp = model.feature_importances_\n",
    "    names = train_df.drop(columns=[label_column]).columns\n",
    "    top_features = pd.DataFrame({\"feature\": names, \"importance\": imp})\\\n",
    "                        .sort_values(\"importance\", ascending=False)\\\n",
    "                        .head(top_k)[\"feature\"].tolist()\n",
    "    print(f\"XGB Importance Top-{top_k}:\", top_features)\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:54.597710Z",
     "iopub.status.busy": "2025-07-24T13:51:54.596840Z",
     "iopub.status.idle": "2025-07-24T13:51:54.601802Z",
     "shell.execute_reply": "2025-07-24T13:51:54.601063Z",
     "shell.execute_reply.started": "2025-07-24T13:51:54.597684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# corr\n",
    "def get_top_corr_features(train_df, label_column, top_k=50):\n",
    "    corrs = train_df.corr(numeric_only=True)[label_column].abs().sort_values(ascending=False)\n",
    "    top_features = corrs.index[1:top_k+1].tolist()\n",
    "    print(f\"Correlation Top-{top_k}:\", top_features)\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:54.771829Z",
     "iopub.status.busy": "2025-07-24T13:51:54.771569Z",
     "iopub.status.idle": "2025-07-24T13:51:54.775291Z",
     "shell.execute_reply": "2025-07-24T13:51:54.774700Z",
     "shell.execute_reply.started": "2025-07-24T13:51:54.771812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_all_features(train_df, label_column):\n",
    "    return [col for col in train_df.columns if col != label_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:54.943248Z",
     "iopub.status.busy": "2025-07-24T13:51:54.942392Z",
     "iopub.status.idle": "2025-07-24T13:51:54.948136Z",
     "shell.execute_reply": "2025-07-24T13:51:54.947328Z",
     "shell.execute_reply.started": "2025-07-24T13:51:54.943212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# try 1:\n",
    "selected_features = [\n",
    "    \"buy_qty\", \"sell_qty\", \"volume\", \"bid_qty\", \"ask_qty\",\n",
    "    'X22', 'X28', 'X40', 'X52', 'X55', 'X97', 'X137', 'X138', 'X168', 'X169', 'X174', 'X175', 'X178',\n",
    "    'X179', 'X180', 'X181', 'X173', 'X197', 'X198', 'X272', 'X288', 'X297', 'X302', 'X321', 'X333',\n",
    "    'X338', 'X341', 'X343', 'X344', 'X345', 'X363', 'X379', 'X385', 'X386', 'X415', 'X421', 'X427',\n",
    "    'X428', 'X435', 'X438', 'X444', 'X445', 'X450', 'X452', 'X459', 'X466', 'X586', 'X587', 'X593',\n",
    "    'X598', 'X572', 'X603', 'X605', 'X612', 'X674', 'X680', 'X683', 'X686', 'X692', 'X695', 'X696', 'X532'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:55.070786Z",
     "iopub.status.busy": "2025-07-24T13:51:55.070159Z",
     "iopub.status.idle": "2025-07-24T13:51:55.080575Z",
     "shell.execute_reply": "2025-07-24T13:51:55.079903Z",
     "shell.execute_reply.started": "2025-07-24T13:51:55.070763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    data = df.copy()\n",
    "    features_df = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    features_df['bid_ask_spread_proxy'] = data['ask_qty'] - data['bid_qty']\n",
    "    features_df['total_liquidity'] = data['bid_qty'] + data['ask_qty']\n",
    "    features_df['trade_imbalance'] = data['buy_qty'] - data['sell_qty']\n",
    "    features_df['total_trades'] = data['buy_qty'] + data['sell_qty']\n",
    "    \n",
    "    features_df['volume_per_trade'] = data['volume'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n",
    "    features_df['buy_volume_ratio'] = data['buy_qty'] / (data['volume'] + 1e-8)\n",
    "    features_df['sell_volume_ratio'] = data['sell_qty'] / (data['volume'] + 1e-8)\n",
    "    \n",
    "    features_df['buying_pressure'] = data['buy_qty'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n",
    "    features_df['selling_pressure'] = data['sell_qty'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n",
    "    \n",
    "    features_df['order_imbalance'] = (data['bid_qty'] - data['ask_qty']) / (data['bid_qty'] + data['ask_qty'] + 1e-8)\n",
    "    features_df['order_imbalance_abs'] = np.abs(features_df['order_imbalance'])\n",
    "    features_df['bid_liquidity_ratio'] = data['bid_qty'] / (data['volume'] + 1e-8)\n",
    "    features_df['ask_liquidity_ratio'] = data['ask_qty'] / (data['volume'] + 1e-8)\n",
    "    features_df['market_depth'] = data['bid_qty'] + data['ask_qty']\n",
    "    features_df['depth_imbalance'] = features_df['market_depth'] - data['volume']\n",
    "    \n",
    "    features_df['buy_sell_ratio'] = data['buy_qty'] / (data['sell_qty'] + 1e-8)\n",
    "    features_df['bid_ask_ratio'] = data['bid_qty'] / (data['ask_qty'] + 1e-8)\n",
    "    features_df['volume_liquidity_ratio'] = data['volume'] / (data['bid_qty'] + data['ask_qty'] + 1e-8)\n",
    "\n",
    "    features_df['buy_volume_product'] = data['buy_qty'] * data['volume']\n",
    "    features_df['sell_volume_product'] = data['sell_qty'] * data['volume']\n",
    "    features_df['bid_ask_product'] = data['bid_qty'] * data['ask_qty']\n",
    "    \n",
    "    features_df['market_competition'] = (data['buy_qty'] * data['sell_qty']) / ((data['buy_qty'] + data['sell_qty']) + 1e-8)\n",
    "    features_df['liquidity_competition'] = (data['bid_qty'] * data['ask_qty']) / ((data['bid_qty'] + data['ask_qty']) + 1e-8)\n",
    "    \n",
    "    total_activity = data['buy_qty'] + data['sell_qty'] + data['bid_qty'] + data['ask_qty']\n",
    "    features_df['market_activity'] = total_activity\n",
    "    features_df['activity_concentration'] = data['volume'] / (total_activity + 1e-8)\n",
    "    \n",
    "    features_df['info_arrival_rate'] = (data['buy_qty'] + data['sell_qty']) / (data['volume'] + 1e-8)\n",
    "    features_df['market_making_intensity'] = (data['bid_qty'] + data['ask_qty']) / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n",
    "    features_df['effective_spread_proxy'] = np.abs(data['buy_qty'] - data['sell_qty']) / (data['volume'] + 1e-8)\n",
    "    \n",
    "    lambda_decay = 0.95\n",
    "    ofi = data['buy_qty'] - data['sell_qty']\n",
    "    features_df['order_flow_imbalance_ewm'] = ofi.ewm(alpha=1-lambda_decay).mean()\n",
    "\n",
    "    features_df = features_df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:56.862574Z",
     "iopub.status.busy": "2025-07-24T13:51:56.862327Z",
     "iopub.status.idle": "2025-07-24T13:51:56.866856Z",
     "shell.execute_reply": "2025-07-24T13:51:56.866158Z",
     "shell.execute_reply.started": "2025-07-24T13:51:56.862557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    TRAIN_PATH = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n",
    "    TEST_PATH = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n",
    "    SUBMISSION_PATH = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n",
    "\n",
    "    FEATURES = []\n",
    "    # train_df = pd.read_parquet(Config.TRAIN_PATH)\n",
    "    # top_features = get_top_corr_features(train_df, Config.LABEL_COLUMN, top_k=50)\n",
    "    # Config.FEATURES = top_features\n",
    "    \n",
    "    LABEL_COLUMN = \"label\"\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    RIDGE_PARAMS = {'alpha': 1.0}\n",
    "\n",
    "MODELS = [\n",
    "    (\"ridge\", Ridge, Config.RIDGE_PARAMS),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:57.084652Z",
     "iopub.status.busy": "2025-07-24T13:51:57.083976Z",
     "iopub.status.idle": "2025-07-24T13:51:57.088951Z",
     "shell.execute_reply": "2025-07-24T13:51:57.087993Z",
     "shell.execute_reply.started": "2025-07-24T13:51:57.084619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(features):\n",
    "    df = pd.read_parquet(Config.TRAIN_PATH)\n",
    "    derived = add_features(df)\n",
    "    df = pd.concat([df, derived], axis=1)\n",
    "    X = df[Config.FEATURES].values\n",
    "    y = df[Config.LABEL_COLUMN].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:58.826773Z",
     "iopub.status.busy": "2025-07-24T13:51:58.826199Z",
     "iopub.status.idle": "2025-07-24T13:51:58.831248Z",
     "shell.execute_reply": "2025-07-24T13:51:58.830335Z",
     "shell.execute_reply.started": "2025-07-24T13:51:58.826745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_and_scale(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False, random_state=Config.RANDOM_STATE\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    return X_train_scaled, X_val_scaled, y_train, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:59.011262Z",
     "iopub.status.busy": "2025-07-24T13:51:59.011054Z",
     "iopub.status.idle": "2025-07-24T13:51:59.015345Z",
     "shell.execute_reply": "2025-07-24T13:51:59.014819Z",
     "shell.execute_reply.started": "2025-07-24T13:51:59.011247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    corr = pearsonr(y_val, y_pred)[0]\n",
    "    return {\"R2\": r2, \"RMSE\": rmse, \"Corr\": corr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:59.133096Z",
     "iopub.status.busy": "2025-07-24T13:51:59.132868Z",
     "iopub.status.idle": "2025-07-24T13:51:59.137346Z",
     "shell.execute_reply": "2025-07-24T13:51:59.136573Z",
     "shell.execute_reply.started": "2025-07-24T13:51:59.133080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(scaler):\n",
    "    test_df = pd.read_parquet(Config.TEST_PATH)\n",
    "    derived = add_features(test_df)\n",
    "    test_df = pd.concat([test_df, derived], axis=1)\n",
    "    X_test = test_df[Config.FEATURES].values\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:51:59.268762Z",
     "iopub.status.busy": "2025-07-24T13:51:59.268513Z",
     "iopub.status.idle": "2025-07-24T13:51:59.272884Z",
     "shell.execute_reply": "2025-07-24T13:51:59.272246Z",
     "shell.execute_reply.started": "2025-07-24T13:51:59.268743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_submission(model, X_test_scaled, filename=\"submission.csv\"):\n",
    "    submission = pd.read_csv(Config.SUBMISSION_PATH)\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    submission[\"prediction\"] = preds\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(\"완\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:52:01.186226Z",
     "iopub.status.busy": "2025-07-24T13:52:01.185972Z",
     "iopub.status.idle": "2025-07-24T13:52:01.190055Z",
     "shell.execute_reply": "2025-07-24T13:52:01.189256Z",
     "shell.execute_reply.started": "2025-07-24T13:52:01.186209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X, y = load_train_data()\n",
    "# X_train, X_val, y_train, y_val, scaler = split_and_scale(X, y)\n",
    "\n",
    "# for model_name, ModelClass, params in MODELS:\n",
    "#     print(f\"\\n모델: {model_name.upper()}\")\n",
    "#     model = ModelClass(**params)\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     scores = evaluate_model(model, X_val, y_val)\n",
    "#     print(f\"{model_name.upper()} 평가 결과: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:52:01.723386Z",
     "iopub.status.busy": "2025-07-24T13:52:01.722823Z",
     "iopub.status.idle": "2025-07-24T13:52:01.728495Z",
     "shell.execute_reply": "2025-07-24T13:52:01.727561Z",
     "shell.execute_reply.started": "2025-07-24T13:52:01.723361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_class, model_params, feature_selector_fn, top_k=50):\n",
    "    print(\"\\n[학습/검증 시작]\")\n",
    "    train_df = pd.read_parquet(Config.TRAIN_PATH)\n",
    "\n",
    "    features = feature_selector_fn(train_df, Config.LABEL_COLUMN, top_k = top_k)\n",
    "    features = list(dict.fromkeys(base_features + features))\n",
    "    Config.FEATURES = features\n",
    "\n",
    "    X, y = load_train_data(features=Config.FEATURES)\n",
    "    X_train, X_val, y_train, y_val, scaler = split_and_scale(X, y)\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    scores = evaluate_model(model, X_val, y_val)\n",
    "    print(f\"평가 결과 (R2={scores['R2']:.4f}, RMSE={scores['RMSE']:.4f}, Corr={scores['Corr']:.4f})\")\n",
    "    return model, scaler, Config.FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:52:03.260566Z",
     "iopub.status.busy": "2025-07-24T13:52:03.259849Z",
     "iopub.status.idle": "2025-07-24T13:52:03.266914Z",
     "shell.execute_reply": "2025-07-24T13:52:03.266031Z",
     "shell.execute_reply.started": "2025-07-24T13:52:03.260538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_stacking(feature_selector_fn, top_k=50):\n",
    "    print(\"\\n[Stacking 학습/검증 시작]\")\n",
    "    train_df = pd.read_parquet(Config.TRAIN_PATH)\n",
    "    features = feature_selector_fn(train_df, Config.LABEL_COLUMN, top_k=top_k)\n",
    "    features = list(dict.fromkeys(base_features + features))\n",
    "    Config.FEATURES = features # + base_features\n",
    "\n",
    "    X, y = load_train_data(features=Config.FEATURES)\n",
    "    X_train, X_val, y_train, y_val, scaler = split_and_scale(X, y)\n",
    "\n",
    "    # Base models\n",
    "    ridge = Ridge(alpha=1.0, random_state=Config.RANDOM_STATE)\n",
    "    xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=Config.RANDOM_STATE, tree_method=\"hist\")\n",
    "    lgbm = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=Config.RANDOM_STATE)\n",
    "\n",
    "    stack_model = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('ridge', ridge),\n",
    "            ('xgb', xgb),\n",
    "            ('lgbm', lgbm)\n",
    "        ],\n",
    "        final_estimator=Ridge(alpha=1.0),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    stack_model.fit(X_train, y_train)\n",
    "    y_pred = stack_model.predict(X_val)\n",
    "    scores = evaluate_model(stack_model, X_val, y_val)\n",
    "    print(f\"Stacking 평가 결과 (R2={scores['R2']:.4f}, RMSE={scores['RMSE']:.4f}, Corr={scores['Corr']:.4f})\")\n",
    "    return stack_model, scaler, Config.FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:52:24.211173Z",
     "iopub.status.busy": "2025-07-24T13:52:24.210925Z",
     "iopub.status.idle": "2025-07-24T13:52:24.215929Z",
     "shell.execute_reply": "2025-07-24T13:52:24.215185Z",
     "shell.execute_reply.started": "2025-07-24T13:52:24.211157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# selected feature 를 사용했을 때,\n",
    "def train_with_selected_features(model_class, model_params, features):\n",
    "    print(\"\\n[selected feature 학습]\")\n",
    "    train_df = pd.read_parquet(Config.TRAIN_PATH)\n",
    "    Config.FEATURES = features\n",
    "\n",
    "    X, y = load_train_data(features=Config.FEATURES)\n",
    "    X_train, X_val, y_train, y_val, scaler = split_and_scale(X, y)\n",
    "\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    scores = evaluate_model(model, X_val, y_val)\n",
    "    print(f\"평가 결과 (R2={scores['R2']:.4f}, RMSE={scores['RMSE']:.4f}, Corr={scores['Corr']:.4f})\")\n",
    "    return model, scaler, features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:52:25.071996Z",
     "iopub.status.busy": "2025-07-24T13:52:25.071295Z",
     "iopub.status.idle": "2025-07-24T13:52:25.075874Z",
     "shell.execute_reply": "2025-07-24T13:52:25.075089Z",
     "shell.execute_reply.started": "2025-07-24T13:52:25.071969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_and_submit(model, scaler, features, filename=\"submission.csv\"):\n",
    "    Config.FEATURES = features\n",
    "    X_test = load_test_data(scaler)\n",
    "    create_submission(model, X_test, filename=filename)\n",
    "    print(f\"완: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T12:34:34.327685Z",
     "iopub.status.busy": "2025-07-24T12:34:34.327364Z",
     "iopub.status.idle": "2025-07-24T12:34:34.423264Z",
     "shell.execute_reply": "2025-07-24T12:34:34.422267Z",
     "shell.execute_reply.started": "2025-07-24T12:34:34.327667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1234002255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model, scaler, features = train_and_evaluate(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRIDGE_PARAMS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# feature들을 바꿀 때,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeature_selector_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_top_corr_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ridge' is not defined"
     ]
    }
   ],
   "source": [
    "model, scaler, features = train_and_evaluate(\n",
    "    model_class=Ridge,\n",
    "    model_params=Config.RIDGE_PARAMS,\n",
    "    # feature들을 바꿀 때,\n",
    "    feature_selector_fn=get_top_corr_features\n",
    "    # feature_selector_fn=get_all_features,\n",
    "    # top_k=50\n",
    ")\n",
    "\n",
    "predict_and_submit(model, scaler, features, filename=\"ridge_corr_submission.csv\")\n",
    "# predict_and_submit(model, scaler, features, filename=\"ridge_full_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T13:52:30.504765Z",
     "iopub.status.busy": "2025-07-24T13:52:30.504470Z",
     "iopub.status.idle": "2025-07-24T14:07:18.990058Z",
     "shell.execute_reply": "2025-07-24T14:07:18.989043Z",
     "shell.execute_reply.started": "2025-07-24T13:52:30.504742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stacking 학습/검증 시작]\n",
      "Correlation Top-50: ['X752', 'X21', 'X20', 'X28', 'X759', 'X29', 'X19', 'X27', 'X22', 'X754', 'X219', 'X756', 'X287', 'X289', 'X291', 'X293', 'X753', 'X295', 'X614', 'X218', 'X751', 'X297', 'X298', 'X285', 'X300', 'X299', 'X302', 'X26', 'X292', 'X301', 'X294', 'X296', 'X303', 'X283', 'X30', 'X465', 'X18', 'X466', 'X181', 'X288', 'X290', 'X286', 'X281', 'X217', 'X175', 'X757', 'X226', 'X225', 'X23', 'X508']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.555847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14025\n",
      "[LightGBM] [Info] Number of data points in the train set: 336566, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 0.044017\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.512143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14025\n",
      "[LightGBM] [Info] Number of data points in the train set: 336566, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 0.024483\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.550792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14025\n",
      "[LightGBM] [Info] Number of data points in the train set: 336566, number of used features: 55\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.514878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14025\n",
      "[LightGBM] [Info] Number of data points in the train set: 336567, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 0.028954\n",
      "[LightGBM] [Info] Start training from score 0.020782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.311068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14025\n",
      "[LightGBM] [Info] Number of data points in the train set: 336567, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 0.009958\n",
      "Stacking 평가 결과 (R2=0.0059, RMSE=1.0361, Corr=0.1206)\n",
      "완\n",
      "완: stacking_submission.csv\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14025\n",
      "[LightGBM] [Info] Number of data points in the train set: 420708, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 0.025639\n"
     ]
    }
   ],
   "source": [
    "stack_model, scaler, features = train_and_evaluate_stacking(\n",
    "    feature_selector_fn=get_top_corr_features,\n",
    "    top_k=50\n",
    ")\n",
    "predict_and_submit(stack_model, scaler, features, filename=\"stacking_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T12:26:55.967564Z",
     "iopub.status.busy": "2025-07-23T12:26:55.967273Z",
     "iopub.status.idle": "2025-07-23T12:26:55.972155Z",
     "shell.execute_reply": "2025-07-23T12:26:55.971214Z",
     "shell.execute_reply.started": "2025-07-23T12:26:55.967540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# selected_feature 사용했을 때,\n",
    "# model, scaler, features = train_with_selected_features(Ridge, Config.RIDGE_PARAMS, selected_features)\n",
    "\n",
    "# predict_and_submit(model, scaler, features, filename=\"ridge_selected_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과\n",
    "- Ridge + corr feature : (R2=-0.0297, RMSE=1.0545, Corr=0.1206)\n",
    "- Stacking(Ridge, xgbm, lgbm) + corr feature : (R2=0.0023, RMSE=1.0380, Corr=0.1183)\n",
    "- Stacking(Ridge, xgbm, lgbm) + corr feature + base_feature : (R2=0.0059, RMSE=1.0361, Corr=0.1206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12993472,
     "sourceId": 96164,
     "sourceType": "competition"
    },
    {
     "sourceId": 241498692,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
